{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d352e93",
   "metadata": {},
   "source": [
    "### Import Require Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2405239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568b089",
   "metadata": {},
   "source": [
    "### Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07a12018",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {'U':(-1,0), 'D':(1,0),'R':(0,1),'L':(0,-1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a2017",
   "metadata": {},
   "source": [
    "### Creating the Maze class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08b14ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze():\n",
    "    def __init__(self, input_maze):\n",
    "        \n",
    "#         self.maze = np.zeros((8,8))\n",
    "#         self.maze[0, 0] = 2\n",
    "#         self.maze[0, 1:6] = 1\n",
    "#         self.maze[:4, 7] = 1\n",
    "#         self.maze[2:6, 1] = 1\n",
    "#         self.maze[2:6, 5] = 1\n",
    "#         self.maze[7, :6] = 1\n",
    "#         self.maze[5, 3:7] = 1\n",
    "#         self.maze[4, 4:7] = 1\n",
    "#         self.maze[3, 3] = 1\n",
    "#         self.maze[3, 6] = 1\n",
    "\n",
    "        self.maze = input_maze\n",
    "        \n",
    "        self.robot_position = (0,0)\n",
    "        self.steps = 0\n",
    "        \n",
    "        self.allowed_states = None\n",
    "        self.construct_allowed_states()\n",
    "    \n",
    "    def print_G_with_maze(self, g_dict):\n",
    "        for row in range(len(self.maze)):\n",
    "            for col in range(len(self.maze)):\n",
    "                if self.maze[row][col]==0:\n",
    "                    print('%.1f' % g_dict[(row,col)], end=\"\\t\")\n",
    "                elif self.maze[row][col]==1:\n",
    "                    print(\"X\", end=\"\\t\")\n",
    "                elif self.maze[row][col]==2:\n",
    "                    print(\"R\", end=\"\\t\")\n",
    "            print() \n",
    "    \n",
    "    def print_maze(self):\n",
    "        print('The input maze:\\n')\n",
    "        for i in self.maze:\n",
    "            for j in i:\n",
    "                if j==0:\n",
    "                    print(\"0\",end=\"\\t\")\n",
    "                elif j==1:\n",
    "                    print(\"X\", end=\"\\t\")\n",
    "                elif j==2:\n",
    "                    print(\"R\", end=\"\\t\")\n",
    "            print()\n",
    "    \n",
    "    def is_allowed_move(self, state, action):\n",
    "        row, col = state\n",
    "        updated_row = row + actions[action][0]\n",
    "        updated_col = col + actions[action][1]\n",
    "        \n",
    "        maze_size = len(self.maze)\n",
    "        \n",
    "        if (0<=updated_row<maze_size and 0<=updated_col<maze_size) and (self.maze[updated_row][updated_col] in [0,2]):\n",
    "            return True\n",
    "       \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def construct_allowed_states(self):\n",
    "        self.allowed_states = {}\n",
    "        \n",
    "        for row in range(len(self.maze)):\n",
    "            for col in range(len(self.maze)):\n",
    "                if self.maze[row][col] != 1:\n",
    "                    self.allowed_states[(row,col)] = []\n",
    "                    \n",
    "                    for action in actions:\n",
    "#                         print('({0},{1}) action:{2} => {3}'.format(row,col, action, self.is_allowed_move((row, col), action)))\n",
    "                        if self.is_allowed_move((row, col), action):\n",
    "                            self.allowed_states[(row,col)].append(action)\n",
    "    \n",
    "    # update maze and robot position \n",
    "    def update_maze(self, action): \n",
    "        row, col = self.robot_position\n",
    "        self.maze[row][col] = 0\n",
    "        \n",
    "        row += actions[action][0]\n",
    "        col += actions[action][1]\n",
    "        \n",
    "        self.robot_position = (row, col)\n",
    "        self.maze[row][col] = 2\n",
    "        self.steps += 1\n",
    "    \n",
    "    def is_game_over(self):\n",
    "        if self.robot_position == (7,7):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def give_reward(self):\n",
    "        if self.robot_position == (7,7):\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def get_state_and_reward(self):\n",
    "        return self.robot_position, self.give_reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0514013d",
   "metadata": {},
   "source": [
    "### Creating Agent Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6702c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, states, alpha=0.15, random_factor=0.2):\n",
    "        self.state_history = [((0, 0), 0)] # state, reward\n",
    "        self.alpha = alpha\n",
    "        self.random_factor = random_factor\n",
    "        \n",
    "        # rewards table\n",
    "        self.G = {}\n",
    "        self.init_reward(states) # states is maze\n",
    "    \n",
    "    def init_reward(self, states):\n",
    "        for row in range(len(states)):\n",
    "            for col in range(len(states)):\n",
    "#           for key in states.keys():\n",
    "                self.G[(row,col)] = np.random.uniform(high=1.0, low=0.1)\n",
    "#                 self.G[key] = np.random.uniform(high=1.0, low=0.1)\n",
    "    \n",
    "    def update_state_history(self, state, reward):\n",
    "        self.state_history.append((state, reward))\n",
    "    \n",
    "    def learn(self):\n",
    "        target = 0 # we know the \"ideal\" reward at (7,7)\n",
    "        a = self.alpha\n",
    "        \n",
    "        for state, reward in reversed(self.state_history):\n",
    "            self.G[state] = self.G[state] + a * (target - self.G[state])\n",
    "            target += reward\n",
    "            \n",
    "        self.state_history = [] # reset the state_history\n",
    "        self.random_factor -= 10e-5\n",
    "    \n",
    "    def choose_action(self, state, allowed_moves):\n",
    "        next_move = None\n",
    "        \n",
    "        n = np.random.random()\n",
    "        \n",
    "        if n<self.random_factor:\n",
    "            next_move = np.random.choice(allowed_moves)\n",
    "        else:\n",
    "            maxG = -10e15\n",
    "            \n",
    "            for action in allowed_moves:\n",
    "#                     print([x for x in zip(state, actions[action])]) \n",
    "                new_state = tuple([sum(x) for x in zip(state, actions[action])]) # summation of two tupples\n",
    "            \n",
    "                if self.G[new_state] >= maxG:\n",
    "                    next_move = action\n",
    "                    maxG = self.G[new_state]\n",
    "        \n",
    "        return next_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4b393",
   "metadata": {},
   "source": [
    "### Input Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a0a8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_maze = [\n",
    "                [2, 1, 1, 1, 1, 1, 0, 1],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [0, 1, 0, 0, 0, 1, 0, 1],\n",
    "                [0, 1, 0, 1, 0, 1, 1, 1],\n",
    "                [0, 1, 0, 0, 1, 1, 1, 0],\n",
    "                [0, 1, 0, 1, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [1, 1, 1, 1, 1, 1, 0, 0]\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09833797",
   "metadata": {},
   "source": [
    "### Craeting the maze and robot instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b41354f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input maze:\n",
      "\n",
      "R\tX\tX\tX\tX\tX\t0\tX\t\n",
      "0\t0\t0\t0\t0\t0\t0\tX\t\n",
      "0\tX\t0\t0\t0\tX\t0\tX\t\n",
      "0\tX\t0\tX\t0\tX\tX\tX\t\n",
      "0\tX\t0\t0\tX\tX\tX\t0\t\n",
      "0\tX\t0\tX\tX\tX\tX\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "X\tX\tX\tX\tX\tX\t0\t0\t\n"
     ]
    }
   ],
   "source": [
    "maze = Maze(create_maze)\n",
    "maze.print_maze()\n",
    "# robot = Agent(maze.allowed_state, alpha=0.1, random_factor=0.25)\n",
    "robot = Agent(maze.maze, alpha=0.1, random_factor=0.25)\n",
    "# maze.allowed_states\n",
    "# maze.construct_allowed_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19228b67",
   "metadata": {},
   "source": [
    "###  Learning Proccess for the Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "671d1134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input maze:\n",
      "\n",
      "R\tX\tX\tX\tX\tX\t0\tX\t\n",
      "0\t0\t0\t0\t0\t0\t0\tX\t\n",
      "0\tX\t0\t0\t0\tX\t0\tX\t\n",
      "0\tX\t0\tX\t0\tX\tX\tX\t\n",
      "0\tX\t0\t0\tX\tX\tX\t0\t\n",
      "0\tX\t0\tX\tX\tX\tX\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "X\tX\tX\tX\tX\tX\t0\t0\t\n",
      "\n",
      "Robot will always choose a step which reward is more close to zero.\n",
      "-14.0\tX\tX\tX\tX\tX\t-602.6\tX\t\n",
      "-12.0\t-14.6\t-27.7\t-218.6\t-426.0\t-411.3\tR\tX\t\n",
      "-11.0\tX\t-40.5\t-246.9\t-467.5\tX\t-456.1\tX\t\n",
      "-10.0\tX\t-114.4\tX\t-576.9\tX\tX\tX\t\n",
      "-9.0\tX\t-65.1\t-224.8\tX\tX\tX\t-16.9\t\n",
      "-8.0\tX\t-7.2\tX\tX\tX\tX\t-1.4\t\n",
      "-7.0\t-6.0\t-5.0\t-4.0\t-3.0\t-2.0\t-1.0\t-0.0\t\n",
      "X\tX\tX\tX\tX\tX\t-0.4\tR\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maze.print_maze()\n",
    "print()\n",
    "\n",
    "moveHistory = []\n",
    "\n",
    "min_steps = float('inf') \n",
    "\n",
    "for i in range(5000):\n",
    "    if i == 4999:\n",
    "        print('Robot will always choose a step which reward is more close to zero.')\n",
    "        maze.print_G_with_maze(robot.G)\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    while not maze.is_game_over():\n",
    "        state, reward = maze.get_state_and_reward()\n",
    "        action = robot.choose_action(state, maze.allowed_states[state])\n",
    "        maze.update_maze(action)\n",
    "        state, reward = maze.get_state_and_reward()\n",
    "        robot.update_state_history(state, reward)\n",
    "        \n",
    "        if maze.steps > 1000:\n",
    "            maze.robot_position = (7,7)\n",
    "        \n",
    "    robot.learn()\n",
    "    \n",
    "    if min_steps > maze.steps:\n",
    "        min_steps = maze.steps\n",
    "        moveHistory = robot.state_history\n",
    "    \n",
    "    maze = Maze(create_maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e85d9f",
   "metadata": {},
   "source": [
    "### Final Choosen Path by The Robor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c4d4fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot optimal movement:\n",
      "R\t1\t1\t1\t1\t1\t0\t1\t\n",
      "R\t0\t0\t0\t0\t0\t2\t1\t\n",
      "R\t1\t0\t0\t0\t1\t0\t1\t\n",
      "R\t1\t0\t1\t0\t1\t1\t1\t\n",
      "R\t1\t0\t0\t1\t1\t1\t0\t\n",
      "R\t1\t0\t1\t1\t1\t1\t0\t\n",
      "R\tR\tR\tR\tR\tR\tR\t0\t\n",
      "1\t1\t1\t1\t1\t1\tR\tR\t\n"
     ]
    }
   ],
   "source": [
    "print('Robot optimal movement:')\n",
    "\n",
    "copy_maze = create_maze.copy()\n",
    "copy_maze[0][0] = 'R'\n",
    "for item in moveHistory:\n",
    "    \n",
    "    copy_maze[item[0][0]][item[0][1]] = 'R'    \n",
    "\n",
    "for i in range(len(copy_maze)):\n",
    "    for j in range(len(copy_maze)):\n",
    "        print(copy_maze[i][j], end='\\t')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
