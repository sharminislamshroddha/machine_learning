# Machine Learning
**It is the process of teaching computers to learn from data.**<br>
There are three types of ML: 
* Supervised learning
* Unsupervised learning
* Reinforcement learning

<br>

## File Descriptions:

**001_pandas_titanic_dataset.ipynb** => This code operates on a Pandas DataFrame and performs data manipulation and analysis tasks. It includes functionality to load, clean, transform, and analyze tabular data. The code utilizes various Pandas methods and functions to handle missing values, apply filters and conditions, compute statistical measures, perform aggregations, and visualize data.


**002_svm_classification_cancer_dataset.ipynb** => In this project, Support Vector Classification (SVC) has been applied to the cancer dataset, which was loaded from the scikit-learn datasets library. The goal of this project is to build a classification model using SVC to accurately classify tumors as either benign or malignant based on various features provided in the dataset.


**003_svm_regression_diabetes.ipynb** => A Support Vector Machine (SVM) regression model has been implemented to predict diabetes progression in patients using the diabetes dataset. The diabeties dataset was loaded from the scikit-learn datasets library.


**004_decision_tree_and_random_forest_model.ipynb** => Feature extraction from dataset, Creating the DecisionTreeRegressor() and RandomForestRegressor() model using scikit-learn library.


**005_titanic_dataset_random_forest_classifier.ipynb** =>  A Random Forest Classifier model has been implemented to predict the survival outcomes of passengers on the Titanic. Also Data pre-processing and feature extraction, Shuffle and split the dataset into test and train data and accuracy checking etc has been implemented in this code.


**006_svc_pipeline_without_library.ipynb** => A SVC model pipeline has been implemented without relying on external libraries. Specially the data preprocessing steps has been implemented withous using any pipeline library.


**007_random_forest_regressor_pipeline_using_library.ipynb** => A Random Forest Regressor pipeline has been implemented using the pipeline function from the scikit-learn library. This notebook demonstrates how the pipeline function simplifies the code by streamlining the data preprocessing and modeling steps.


**008_end_to_end_machine_learning_project.ipynb** => This project focuses on implementing a complete end-to-end machine learning workflow, covering tasks such as data exploration, preprocessing, feature engineering, model selection, and evaluation. This implemented code provides practical insights and guidance for building robust machine learning pipelines from start to finish.


**009_ensemble_learning.ipynb** => This file features a Python code implementation of various ensemble learning techniques. It includes popular methods such as voting classifier, bagging, pasting, AdaBoosting, Gradient Boosting, stacking, and XGBoost. These techniques combine multiple models to improve predictive accuracy and robustness. The code provides a practical guide for implementing ensemble learning algorithms using scikit-learn and XGBoost libraries.


**010_clustering.ipynb** => This code presents an analysis of different clustering methods for unsupervised learning. The code demonstrates the implementation of three popular clustering algorithms: Gaussian Mixture Model (GMM), K-means, and DBSCAN.


**011_image_segmentation_using_clustering** => This code demonstrates the application of KMeans clustering algorithm for image segmentation. 


**012_semi_supervised_learning_using_clustering.ipynb** => The code demonstrates how clustering techniques can be employed to leverage unlabeled data in combination with limited labeled data to improve classification performance.


**013_dimensionality_reduction.ipynb** => This project focuses on implementing unsupervised learning algorithms. Here, the code represents the effects of different dimensionality reduction models on the MNIST dataset from scikit-learn. It provides visualizations and analysis of the dataset before and after applying techniques like PCA. Also t-SNE, LDA and Random Projection have been implemented in this file of codes. The goal is to understand how these models impact the dataset's dimensionality.


**014_maze_reinforcement_learning.ipynb** => This project focuses on implementing a reinforcement learning algorithm to solve a maze problem. It demonstrates how an agent can learn to navigate and find the optimal path through a maze environment using reinforcement learning techniques.
